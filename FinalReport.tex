\documentclass[12pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{setspace}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{array}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{float}
\graphicspath{{Diagrams/}}

% Double spacing per assignment requirements
\doublespacing

\title{Cloud-Based YouTube Trending Analytics Pipeline on AWS\\\large CS 6705 Final Project}
\author{Kevin Bell \and Jacob Child}
\date{Fall 2025}

\begin{document}
\maketitle
\tableofcontents
\newpage

\section{Problem Statement and Scope}
YouTube generates millions of daily interactions that indicate which videos are trending across regions. Stakeholders---content creators, advertisers, and platform operators---need timely insight into which videos will continue trending so they can optimize promotion, moderation, and infrastructure. Our project builds an end-to-end cloud pipeline that automatically ingests trending-video metadata and comments, curates reliable analytics datasets, applies sentiment analysis, and produces next-day trending predictions. The scope covers daily ingestion, scalable ETL, feature engineering, model training, and prediction publishing, with an emphasis on low-operations automation, cost control, and reproducibility.\footnote{Implementation details for the trending ETL job are in \texttt{Python/ETL/yt\_trending\_etl.py}.}

\section{Background}
Trending videos on YouTube are built on statistics of views, like, comments and contextual signals such as category, title language and audience sentiment. Industrial data platforms commonly use event-driven ingestion, data lakes for raw and curated layers, and distributed processing (e.g., AWS Glue/Spark) for feature computation. Sentiment-aware features can improve short-term popularity forecasting by capturing viewer reception. Our design follows the medallion architecture: raw JSON lands in Amazon S3, curated Parquet layers standardize schema, and downstream ML consumes labeled feature sets. Compared with single-node notebooks or cron-based scripts, the AWS EventBridge + Lambda + Glue stack provides resiliency, schema evolution through crawlers for both batch and near--real-time updates.

\section{System Architecture and Contributions}
\subsection{End-to-End Flow}
A 6:00 AM EventBridge rule triggers two Lambda functions to fetch trending videos and comments via the YouTube Data API. The trending Lambda then launches a Glue Workflow that chains six ETL jobs, ensuring dependency ordering and eliminating manual coordination. Figure~\ref{fig:flow} summarizes the daily flow.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{FlowDiagram.png}
    \caption{Daily ingestion and ETL orchestration triggered by EventBridge.}
    \label{fig:flow}
\end{figure}

\subsection{Trending ETL}
The \texttt{yt\_trending\_etl.py} Glue job flattens nested API responses, extracts region and trending date from S3 paths, casts metrics, deduplicates by video ID (keeping the highest view count), and enriches timestamps with date, hour, week, and cleaned titles before writing curated Parquet partitioned by region and trending date.\footnote{See \texttt{Python/ETL/yt\_trending\_etl.py}, lines 12--168.}

\subsection{Comments ETL}
The comments ETL normalizes one row per comment, keeps author, text, likes, and published timestamp, and derives region and ingest date from file names. Curated Parquet is appended and partitioned by region and ingest date, ready for sentiment analysis and engagement statistics.\footnote{See \texttt{Python/ETL/yt\_comments\_etl.py}, lines 8--110.}

\subsection{Sentiment and Feature Labeling}
A subsequent Glue job scores each comment with AWS Comprehend to compute per-video averages of positive, negative, neutral, and mixed sentiment. The one-time backfill script joins curated trending data with sentiment, constructs time-window lags and ratios (view/like/comment velocities, growth ratios, engagement per view), derives labels for next-day view growth and continued trending presence, and writes labeled feature sets partitioned by region and ingest date.\footnote{See \texttt{Python/ETL/yt-onetimebatch.py}, lines 1--209, and sentiment schema examples in \texttt{Notes.md}, lines 72--119.}

\subsection{Modeling and Predictions}
Within the Glue workflow, training and prediction steps retrain models on updated labeled features and emit next-day forecasts. Outputs include predicted view counts and probability a video will remain trending, stored as curated Parquet for dashboarding and ad hoc analytics using Amazon Athena.

\subsection{Infrastructure and Security}
A dedicated VPC isolates Glue resources, with public subnets for internet-facing components and private subnets using a NAT Gateway for outbound API and package access. Amazon S3 serves as the data lake for raw, curated, and model outputs. Secrets Manager supplies API credentials to Lambda. Figure~\ref{fig:network} depicts the network design, and the Glue workflow ordering mirrors the medallion progression from raw to curated to ML outputs.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{CorrectNetworkInfrastructure.png}
    \caption{Network architecture: VPC isolation, NAT routing, and service boundaries.}
    \label{fig:network}
\end{figure}

\section{Results and Analysis}
\subsection{Curated Schemas}
The curated trending schema captures identifiers, metrics, time fields, and cleaned titles; the curated comments schema retains author, text, likes, and published timestamp. Example schemas are shown in Table~\ref{tab:schemas}.

\begin{table}[H]
    \centering
    \begin{tabular}{p{0.45\textwidth} p{0.45\textwidth}}
        \toprule
        \textbf{Curated Trending (excerpt)} & \textbf{Curated Comments (excerpt)} \\
        \midrule
        video\_id (string) & video\_id (string) \\
        channel\_id (string) & author\_display\_name (string) \\
        category\_id (string) & comment\_text (string) \\
        title, title\_clean (string) & like\_count (long) \\
        published\_at (timestamp) & published\_at (string) \\
        view/like/comment\_count (long) & region (string) \\
        region (string) & ingest\_date (date) \\
        trending\_date (date) & \\
        \bottomrule
    \end{tabular}
    \caption{Curated schemas summarized from \texttt{Notes.md}.}
    \label{tab:schemas}
\end{table}

\subsection{Sentiment Insights}
Aggregated sentiment features surface audience reception per video and date. Table~\ref{tab:sentiment} highlights example distributions (positive shares commonly above 0.45 with varying negative proportions), offering discriminative signals for trend persistence.

\begin{table}[H]
    \centering
    \begin{tabular}{lcccc}
        \toprule
        \textbf{Video ID} & \textbf{Neg.} & \textbf{Pos.} & \textbf{Neu.} & \textbf{Mix.} \\
        \midrule
        f9cmVvoff\_E & 0.13 & 0.62 & 0.24 & 0.01 \\
        qyG8ECu6PLs & 0.13 & 0.45 & 0.41 & 0.01 \\
        NED7nev2ywQ & 0.03 & 0.59 & 0.37 & 0.00 \\
        5VYsnngkS\_U & 0.27 & 0.48 & 0.22 & 0.02 \\
        sNHHfHIewpU & 0.21 & 0.14 & 0.62 & 0.02 \\
        \bottomrule
    \end{tabular}
    \caption{Sample aggregated comment sentiment scores.}
    \label{tab:sentiment}
\end{table}

\subsection{Feature Engineering and Labels}
Lag-based velocities and growth ratios quantify momentum, while engagement-per-view and log-count transforms stabilize variance across orders of magnitude. Labels track whether a video remains in the trending set on the next ingest date and estimate logarithmic view growth; this framing supports classification for stay-trending probability and regression for view-count prediction.

\subsection{Model Outputs}
Predicted outputs include next-day view counts and probabilities of staying in the trending set. Table~\ref{tab:predictions} shows example rows with high-confidence predictions across diverse videos.

\begin{table}[H]
    \centering
    \begin{tabular}{lrrr}
        \toprule
        \textbf{Video ID} & \textbf{View Count} & \textbf{Predicted Next Views} & \textbf{Prob. Stay Trending} \\
        \midrule
        0UI\_Gc7OYWc & 288{,}166 & 288{,}166 & 1.00 \\
        5VYsnngkS\_U & 7{,}946{,}614 & 7{,}946{,}614 & 1.00 \\
        LuJpdvb5bDk & 4{,}239{,}644 & 4{,}239{,}644 & 1.00 \\
        QKYFfYLe5rs & 5{,}120{,}928 & 5{,}120{,}928 & 1.00 \\
        ppp7dMhzrz8 & 653{,}684 & 653{,}684 & 1.00 \\
        \bottomrule
    \end{tabular}
    \caption{Sample model predictions for next-day trending likelihood.}
    \label{tab:predictions}
\end{table}

\subsection{Operational Considerations}
Using serverless ingestion and managed Spark (Glue) minimized operational burden. Most spend comes from Glue job runtime and NAT egress during package downloads; partition pruning and Parquet compression reduce Athena costs. The workflow's dependency graph lowers failure domains by sequencing ETL stages.

\section{Team Contributions}
\begin{itemize}
    \item \textbf{Kevin Bell}: VPC/network design and Lambda + EventBridge integration; implemented trending ETL, curated schema definitions, and presentation materials documenting the workflow and infrastructure.
    \item \textbf{Jacob Child}: Led architecture for comments ingestion, sentiment processing, and feature/label engineering; authored the backfill job that joins sentiment with trending metrics and produces ML-ready datasets; supported model training and prediction stages.
\end{itemize}
Workload was split evenly, with paired code reviews on each ETL milestone and shared notebook-based data validation.

\section{Conclusion and Future Work}
We delivered an automated, cloud-native YouTube analytics pipeline that ingests daily trending data, curates clean datasets, enriches them with sentiment, engineers predictive features, and outputs next-day trending predictions. The architecture balances scalability and cost, and the modular ETL jobs simplify maintenance. Future enhancements include incremental model retraining with drift detection, additional NLP features from titles/descriptions (e.g., embeddings) and toxicity detection on comments, near--real-time micro-batching for faster trend detection, and expanded dashboards for stakeholder-facing monitoring.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{Screenshot 2025-12-05 123426.png}
    \caption{Top 20 Most Viewed Trending Videos in USA.}
    \label{fig:flow}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{Screenshot 2025-12-05 124348.png}
    \caption{Top 20 Most Viewed Trending Videos in Canada.}
    \label{fig:flow}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{Screenshot 2025-12-05 124536.png}
    \caption{Top 20 Most Viewed Trending Videos in Great Britain.}
    \label{fig:flow}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{Screenshot 2025-12-05 124743.png}
    \caption{Predictions}
    \label{fig:flow}
\end{figure}


\end{document}
